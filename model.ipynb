{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"/Users/aayushjain/codes/project/Fino/project 5/Fino_Payments_Bank.xlsx - Chatter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino Payments Bank  and yt\n",
    "#finopaymentsbank insta\n",
    "#Fino Payments Bank Ltd link\n",
    "#FinoPaymntsBank  twitter\n",
    "\n",
    "data['Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources - Twitter.com,youtube.com, linkedin, Facebook.com' Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Language'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data= data[[                     \n",
    "    'Source' ,                  \n",
    "    'Screenname'  ,      \n",
    "    'Sentiment'   ,       \n",
    "    'Content'   ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = ['Fino Payments Bank', 'finopaymentsbank', 'Fino Payments Bank Ltd', 'FinoPaymntsBank']\n",
    "filtered_data = filtered_data[~filtered_data['Screenname'].isin(removed)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_req=['Twitter.com', 'youtube.com', 'linkedin', 'Facebook.com','Instagram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data[filtered_data['Source'].isin(sources_req)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_piechart(data, column, background_color=None):\n",
    "    sentiment_counts = data[column].value_counts()\n",
    "    \n",
    "    if background_color is None:\n",
    "        background_color = '#ffffff'  # White\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Set colors for positive, negative, and neutral sentiments\n",
    "    colors = {'Positive': 'purple', 'Negative': 'red', 'Neutral': 'white'}\n",
    "    \n",
    "    labels = sentiment_counts.index.tolist()\n",
    "    counts = sentiment_counts.values.tolist()\n",
    "    explode = (0, 0.2, 0.0)  # Explode all slices slightly\n",
    "    \n",
    "    patches, texts, autotexts = ax.pie(counts, labels=None, autopct='%1.1f%%', startangle=140, \n",
    "                                       colors=[colors[label] for label in labels], explode=explode, textprops=dict(color=\"#39FF14\")  )\n",
    "    \n",
    "    #ax.set_title('Sentiment Distribution', color='white')  \n",
    "    ax.axis('equal')  \n",
    "    \n",
    "    ax.set_facecolor(background_color)\n",
    "    \n",
    "    fig.patch.set_facecolor('black')\n",
    "    \n",
    "    for text, label in zip(autotexts, labels):\n",
    "        text.set_text(f'{text.get_text()} - {label}')\n",
    "    \n",
    "    plt.legend(patches, labels, loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_piechart(filtered_data,'Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data_processing import process_csv_file\n",
    "\n",
    "def generate_dashboard(df):\n",
    "    st.title(\"Sentiment Analysis Dashboard\")\n",
    "    \n",
    "    sources = df['Source'].unique()\n",
    "    for source in sources:\n",
    "        st.subheader(f\"Sentiment Distribution for {source}\")\n",
    "        source_data = df[df['Source'] == source]\n",
    "        plot_piechart(source_data, 'Sentiments')\n",
    "\n",
    "def plot_piechart(data, column, background_color=None):\n",
    "    sentiment_counts = data[column].value_counts()\n",
    "    \n",
    "    if background_color is None:\n",
    "        background_color = '#ffffff'  # White\n",
    "    \n",
    "    # Set colors for positive, negative, and neutral sentiments\n",
    "    colors = {'Positive': 'purple', 'Negative': 'red', 'Neutral': 'white'}\n",
    "    \n",
    "    labels = sentiment_counts.index.tolist()\n",
    "    counts = sentiment_counts.values.tolist()\n",
    "    explode = (0, 0.2, 0.0)  # Explode the negative slices slightly\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    patches, texts, autotexts = ax.pie(counts, labels=None, autopct='%1.1f%%', startangle=140, \n",
    "                                       colors=[colors[label] for label in labels], explode=explode,             \n",
    "                                       textprops=dict(color=\"#39FF14\"))  \n",
    "    \n",
    "    ax.axis('equal')  \n",
    "    ax.set_facecolor(background_color)\n",
    "    fig.patch.set_facecolor('black')\n",
    "    \n",
    "    for text, label in zip(autotexts, labels):\n",
    "        text.set_text(f'{text.get_text()} - {label}')\n",
    "    \n",
    "    plt.legend(patches, labels, loc=\"best\")\n",
    "    \n",
    "    st.pyplot(fig)\n",
    "\n",
    "process_csv_file(filtered_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data['Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment_content_dict = {}\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in filtered_data.iterrows():\n",
    "    # Extract sentiment and content values from the current row\n",
    "    sentiment = row['Sentiment']\n",
    "    content = row['Content']\n",
    "    \n",
    "    # Check if sentiment already exists in the dictionary\n",
    "    if sentiment in sentiment_content_dict:\n",
    "        # If sentiment already exists, append the content to its list\n",
    "        sentiment_content_dict[sentiment].append(content)\n",
    "    else:\n",
    "        # If sentiment does not exist, create a new key-value pair\n",
    "        sentiment_content_dict[sentiment] = [content]\n",
    "\n",
    "# Print the dictionary\n",
    "print(sentiment_content_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (862917189.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    'The bank's services are satisfactory.',\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Apply sentiment classification to each row in the dataset\u001b[39;00m\n\u001b[1;32m     34\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabelled_gpt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(classify_sentiment)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4-0125-preview\", temperature=0): \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"system\", \"content\": \"You are a kind business insight employee with speciality in online media sentiment analysis, you work in India's Largest Payments Bank - Fino Payments Bank\"}, \n",
    "        {\"content\": prompt}\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "# Function to classify sentiment based on GPT response\n",
    "def classify_sentiment(text):\n",
    "    # Perform GPT-4 text completion to generate sentiment\n",
    "    sentiment = get_completion(text)\n",
    "    \n",
    "    # Classify sentiment based on GPT-4 response\n",
    "    if \"positive\" in sentiment.lower():\n",
    "        return \"positive\"\n",
    "    elif \"negative\" in sentiment.lower():\n",
    "        return \"negative\"\n",
    "    elif \"constructive\" in sentiment.lower():\n",
    "        return \"constructive\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Apply sentiment classification to each row in the dataset\n",
    "data[\"labelled_gpt\"] = data[\"content\"].apply(classify_sentiment)\n",
    "\n",
    "# Display the updated dataset with the new \"labelled_gpt\" column\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-EcWs5HSy1qlwbKwKhKJAT3BlbkFJ1naQHhncrueR70F00SWE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-0125-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m): \n\u001b[1;32m     11\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a kind business insight employee with speciality in online media sentiment analysis, you work in India\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Largest Payments Bank - Fino Payments Bank\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     13\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[1;32m     14\u001b[0m     ]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def classify_content(content):\n",
    "    prompts = {\n",
    "        'positive': f\"Is the following statement positive? '{content}'\",\n",
    "        'negative': f\"Is the following statement negative? '{content}'\",\n",
    "        'constructive': f\"Is the following statement constructive? '{content}'\",\n",
    "        'neutral': f\"Is the following statement neutral? '{content}'\"\n",
    "    }\n",
    "    \n",
    "    results = {category: get_completion(prompt) for category, prompt in prompts.items()}\n",
    "    \n",
    "    # Extract content from completion messages\n",
    "    result_contents = {category: result['content'] for category, result in results.items()}\n",
    "    \n",
    "    # Determine the sentiment with the highest confidence\n",
    "    max_sentiment = max(result_contents, key=result_contents.get)\n",
    "    \n",
    "    return max_sentiment\n",
    "\n",
    "list_response=[]\n",
    "\n",
    "def labelling(data):\n",
    "   \n",
    "    sentiment_content_dict = {}\n",
    "    for index, row in data.iterrows():\n",
    "        sentiment = row['labelled_gpt']\n",
    "        content = row['Content']\n",
    "        \n",
    "        if sentiment in sentiment_content_dict:\n",
    "            sentiment_content_dict[sentiment].append(content)\n",
    "        else:\n",
    "            sentiment_content_dict[sentiment] = [content]\n",
    "\n",
    "    return sentiment_content_dict\n",
    "\n",
    "def generate_suggestions(api_key,data):\n",
    "    openai.api_key=api_key\n",
    "    data['labelled_gpt'] = data['Content'].apply(classify_content)\n",
    "    dict_obt=labelling(data)\n",
    "    for sentiment in dict_obt.keys():\n",
    "        prompt = f\"\"\" \n",
    "As a business insights expert at Fino Payments Bank.\\\n",
    "You have been given a dataset which has negative, positive, constructive and neutral feedbacks in comments section of different social media platfrom in which Fino Payments Bank is active.\\\n",
    "You are given a task to analyse the {sentiment} \\\n",
    "You must read, remember and analyse all the comments in this section\\\n",
    "After reading them you must present the top 5 findings related to the sentiment\\\n",
    "It should reflect the sentiment of the people, what they feel\\\n",
    "Also, from the analysis you must give a percentage stat of how many comments from the total think the same\\\n",
    "These top 5 most popular talks will be noted by the Directors of the company and will be addressed\n",
    "\"\"\"\n",
    "        response = get_completion(prompt)\n",
    "        list_response.append(response)\n",
    "    return list_response\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "openai.api_key='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'\n",
    "\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4-0125-preview\", temperature=0): \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a kind business insight employee with speciality in online media sentiment analysis, you work in India's Largest Payments Bank - Fino Payments Bank\"},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello, how are you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 16\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model, temperature)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-0125-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m): \n\u001b[1;32m     11\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a kind business insight employee with speciality in online media sentiment analysis, you work in India\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Largest Payments Bank - Fino Payments Bank\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     13\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[0;32m---> 16\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     17\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m     19\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "get_completion(\"hello, how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error: OpenAI version 0.27.8 is less than the required version 1.1.1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m current_version \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(openai\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_version \u001b[38;5;241m<\u001b[39m required_version:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: OpenAI version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopenai\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is less than the required version 1.1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI version is compatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Error: OpenAI version 0.27.8 is less than the required version 1.1.1"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from packaging import version\n",
    "\n",
    "required_version = version.parse(\"1.1.1\")\n",
    "current_version = version.parse(openai.__version__)\n",
    "\n",
    "if current_version < required_version:\n",
    "    raise ValueError(f\"Error: OpenAI version {openai.__version__}\"\n",
    "                     \" is less than the required version 1.1.1\")\n",
    "else:\n",
    "    print(\"OpenAI version is compatible.\")\n",
    "\n",
    "# -- Now we can get to it\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"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\")  # should use env variable OPENAI_API_KEY\n",
    "\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "          },\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "      },\n",
    "    }\n",
    "  }\n",
    "]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4-0125-preview\",\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    "  tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "print(completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "openai.api_key='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'\n",
    "\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4-0125-preview\", temperature=0): \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a kind business insight employee with speciality in online media sentiment analysis, you work in India's Largest Payments Bank - Fino Payments Bank\"},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 15\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model, temperature)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-0125-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m): \n\u001b[1;32m     10\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a kind business insight employee with speciality in online media sentiment analysis, you work in India\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Largest Payments Bank - Fino Payments Bank\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     12\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[0;32m---> 15\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     16\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m     18\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "get_completion(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\",temperature=0): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a kind business insight employee with speciality in online media sentiment analysis, you work in India's Largest Payments Bank - Fino Payments Bank\"},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ]    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'! How can I assist you today with your online media sentiment analysis needs for Fino Payments Bank?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "openai.api_key='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'\n",
    "\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\",temperature=0): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a kind business insight employee with speciality in online media sentiment analysis, you work in India's Largest Payments Bank - Fino Payments Bank\"},\n",
    "        {\"role\": \"assistant\", \"content\": prompt}\n",
    "    ]    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_response=[]\n",
    "\n",
    "def labelling(data):\n",
    "    sentiment_content_dict = {}\n",
    "    for index, row in data.iterrows():\n",
    "        sentiment = row['Sentiment']\n",
    "        content = row['Content']  \n",
    "        if sentiment in sentiment_content_dict:\n",
    "            sentiment_content_dict[sentiment].append(content)\n",
    "        else:\n",
    "            sentiment_content_dict[sentiment] = [content]\n",
    "    return sentiment_content_dict\n",
    "\n",
    "\n",
    "def generate_suggestions(api_key,data):\n",
    "\n",
    "    data = data.sample(n=300, random_state=42)\n",
    "    openai.api_key=api_key\n",
    "\n",
    "    #data['labelled_gpt'] = data['Content'].apply(classify_content)\n",
    "    dict_obt=labelling(data)\n",
    "\n",
    "    for sentiment in dict_obt.keys():\n",
    "        prompt =  f\"\"\" \n",
    "As a business insights expert at Fino Payments Bank.\\\n",
    "You have been given a dataset which has negative, positive, constructive and neutral feedbacks in comments section of different social media platfrom in which Fino Payments Bank is active.\\\n",
    "You are given a task to analyse the {sentiment} \\\n",
    "You must read, remember and analyse all the comments in this section\\\n",
    "After reading them you must present the top 5 findings related to the sentiment\\\n",
    "It should reflect the sentiment of the people, what they feel\\\n",
    "Also, from the analysis you must give a percentage stat of how many comments from the total think the same\\\n",
    "These top 5 most popular talks will be noted by the Directors of the company and will be addressed\\\n",
    "Make sure you return only and only 5 points, thats it and that too in bullet points\n",
    "\"\"\"\n",
    "        response = get_completion(prompt)\n",
    "        list_response.append(response)\n",
    "    return list_response\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"- Customers appreciate the user-friendly interface of Fino Payments Bank's mobile app, making banking transactions convenient and hassle-free.\\n- Many customers have mentioned the quick and efficient customer service provided by Fino Payments Bank, resolving their queries and issues promptly.\\n- Some customers have expressed satisfaction with the wide network of ATMs and banking outlets offered by Fino Payments Bank, making it convenient for them to access banking services.\\n- A few customers have highlighted the security features of Fino Payments Bank, such as two-factor authentication and secure login processes, giving them peace of mind while conducting transactions.\\n- Several customers have praised the transparency in fees and charges levied by Fino Payments Bank, stating that it helps them manage their finances better. \\n\\nPercentage of customers who appreciate these points: 75%\",\n",
       " \"- Many customers are expressing dissatisfaction with the customer service provided by Fino Payments Bank, citing long wait times and unresponsive support staff.\\n- Several customers are unhappy with the fees and charges associated with Fino Payments Bank services, feeling that they are too high compared to other banks.\\n- Some customers have raised concerns about the security of their transactions and personal information while using Fino Payments Bank's digital platforms.\\n- A number of customers have complained about technical issues and glitches when using Fino Payments Bank's mobile app or website, impacting their overall banking experience.\\n- There is a common sentiment among customers that Fino Payments Bank needs to improve its communication and transparency regarding changes in policies or services, as many feel uninformed or confused. \\n\\nPercentage of comments reflecting these sentiments: Approximately 60% of the total comments analyzed.\",\n",
       " \"- Customers appreciate the user-friendly interface of Fino Payments Bank's mobile app, making banking transactions convenient and hassle-free.\\n- Many users commend the quick and efficient customer service provided by Fino Payments Bank, resolving their queries and issues promptly.\\n- Customers express satisfaction with the wide network of ATMs and banking correspondents, ensuring easy access to banking services across various locations.\\n- Users value the security features implemented by Fino Payments Bank, ensuring the safety of their transactions and personal information.\\n- Several customers praise the innovative digital payment solutions offered by Fino Payments Bank, enhancing their overall banking experience.\\n\\nPercentage of positive comments: 75%\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = filtered_data.sample(n=300, random_state=42)\n",
    "\n",
    "generate_suggestions('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',filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
